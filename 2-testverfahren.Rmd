# Testverfahren

Zur Bestimmung der Qualität eines Modells ist es unerlässlich dieses an unbekannten / zukünftigen Daten zu testen. Teilt man die vorliegenden Daten jedoch nur in jeweils einen einzelnen Trainings- und Testdatensatz, können die statistischen Kennzahlen des Modells unter Umständen zu stark davon beeinflusst werden, in welchen Proportionen die unterschiedlichen Klassen in den beiden Datensätzen vorliegen. Dies ist vor allem bei kleineren Stichproben, bzw. Stichproben, in denen eine bestimmte Klasse nur in geringer Proportion vertreten ist, von Bedeutung.  

Um dieses Problem zu lösen bieten sich verschiedene Verfahren an.

## Cross-Validation / Kreuzvalidierung

Ein mittlerweile fast schon als Standard etabliertes Testverfahren ist die sogenannte Cross-validation, bzw. **k-fold corss-validation / k-fold CV**. Dabei werden die Daten zufällig sortiert und in *k* Teilmengen, auch *folds* genannt, unterteilt. Anschließend werden *k* Modelle erstellt, bei denen jeweils eine andere dieser *k* Teilmengen als Testmenge verwendet wird. Jedes Modell wird dann anhand der Performance beim Vorhersagen der Testmenge evaluiert und die über alle Testmengen hinweg durchschnittliche Fehler- oder Erfolgsquote errechnet.
   
   
<br>   
<center>
![cv](img-kfold.gif)
</center>
<br>   

Bei einer **10-fold CV** werden somit für 10 verschiedene Modelle jeweils 90% der Daten für das Training und 10% für das Testing verwendet, wobei es zu 10 verschiedenen Kombinationen aus Trainings- und Testmengen kommt.  

Eine Möglichkeit die Performance eines Modells noch verlässlicher zu testen, ist die **repeated k-fold CV** Methode. Bei dieser wird das jeweilige k-fold CV Verfahren beliebig oft wiederholt und das Ergebnis ebenfalls über den Durchschnitt berechnet. Beispielsweise wird kann dabei ein 10-fold CV zehn mal als Ganzes wiederholt und damit mit zehn unterschiedlichen zufälligen Sortierungen der Fälle durchgeführt werden. 


## Bootstrap sampling / Bootstrapping

Eine Alternative zum k-fold CV ist das sogenannte **Bootstrap sampling / Bootstrapping**. Beim Bootstrap sampling werden mehrere Trainingsdatensätze aus zufällig gewählten Fällen erstellt und die jeweils übrig gebliebenen Fälle für die Ermittlung der Performance des Modells genutzt. Der Entscheidene Unterschied zum k-fold CV ist dabei, dass ein einzelner Fall mehrfach gezogen, also im Trainingsdatensatz verwendet werden kann.  

Im folgenden Beispiel wurde ein Trainingsdatensatz per Bootstrapping erstellt. Der dritte und vierte Fall im Trainingsdatensatz sind identisch. Der im Trainingsdatensatz nicht vorkommende dritte Fall des originalen Datensatzes *(Happy, Yes, 80, Pop)* würde in diesem Fall beim Testen des Modells verwendet werden.

<br>
<center>
![bootstrapping](img-bootstrapping.png)
</center>
